{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow Tracking with Python\n",
    "> - Tested on macOS Monterey version 12.1 Macbook Pro, 2.2 GHz Quad-Core Intel Core i7, Memory 16GB DDR3\n",
    "> - Please go to https://github.com/maximuslee1226/mlflow for notebooks and artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kuzushiji Character Recognition & Classification\n",
    "\n",
    "### Background\n",
    "> \"Kuzushiji is a general term (including hentaigana and cursive kanji) for characters that are not used today.\" \n",
    "\n",
    "> From the Kaggle site, it is stated that Japan has millions of books and over a billion historical documents such as personal letters or diaries preserved nationwide. Most of them cannot be read by the majority of Japanese people living today because they were written in “Kuzushiji”.\n",
    "\n",
    "> Even though Kuzushiji, a cursive writing style, had been used in Japan for over a thousand years, there are very few fluent readers of Kuzushiji today (only 0.01% of modern Japanese natives). Due to the lack of available human resources, there has been a great deal of interest in using Machine Learning to automatically recognize these historical texts and transcribe them into modern Japanese characters.\n",
    "\n",
    "> In this notebook, the author built a deep learning model to transcribe ancient japanese letters into contemporary Japanese character\n",
    "\n",
    "### Notebook Code \n",
    "\n",
    "> - Built hand-written characters recognition system using convolutional neural networks\n",
    "> - Used MLflow for tracking experimetns \n",
    "\n",
    "![Fig1-1: Kuzushiji Characters](http://static.mxbi.net/umgy001-010-smallannomasked.jpg)\n",
    "\n",
    "### References\n",
    "> - DHQ: Ditial Humanities Quarterly: The Kuzushiji Project\n",
    "> - Kuzushiji-MNIST dataset on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn            as nn\n",
    "import torch.optim         as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision      import datasets, transforms\n",
    "from torch.autograd   import Variable\n",
    "\n",
    "import mlflow              as mf\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is now set to cpu\n"
     ]
    }
   ],
   "source": [
    "args = {'batch_size': 4,       \n",
    "        'test_batch_size': 4,       \n",
    "        'epochs': 45,       \n",
    "        'seed': 32,      \n",
    "        'learning_rate': 0.001,    \n",
    "        'momentum': 0.5}     \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Device is now set to {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10,  kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Dataloader Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.KMNIST('../data', train=True,  download=True, transform=transform)\n",
    "test_dataset = datasets.KMNIST('../data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset,  batch_size=args['test_batch_size'], shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args['learning_rate'], momentum=args['momentum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 1000  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.2f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "            step = epoch * len(train_loader) + batch_idx\n",
    "            mf.log_metric('train_loss',  loss.data.item())\n",
    "            \n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct   = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').data.item() \n",
    "            pred = output.data.max(1)[1] \n",
    "            correct += pred.eq(target.data).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nAverage loss for Test dataset: {:.2f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), test_accuracy))\n",
    "        \n",
    "    mf.log_metric('Test loss',     test_loss)\n",
    "    mf.log_metric('Test Accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.set_tracking_uri('http://127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mf.set_experiment(\"Kuzushiji test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa356446970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.49\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.47\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.25\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.58\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.86\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.27\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.32\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.45\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.73\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.60\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.70\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.16\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.30\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.17\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.78\n",
      "\n",
      "Average loss for Test dataset: 0.67, Accuracy: 5363/10000 (54%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.91\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.09\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.87\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.04\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.61\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.37\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.10\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.58\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.76\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.55\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.36\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.73\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.49\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.49\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.87\n",
      "\n",
      "Average loss for Test dataset: 0.58, Accuracy: 5660/10000 (57%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.64\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.60\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.17\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.48\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.45\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.84\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.15\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.12\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.64\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.39\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.40\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.03\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.39\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.49\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.69\n",
      "\n",
      "Average loss for Test dataset: 0.53, Accuracy: 5903/10000 (59%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.53\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.61\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.47\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.19\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.14\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.68\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.25\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.17\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.03\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.11\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.52\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.08\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.04\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.39\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.31\n",
      "\n",
      "Average loss for Test dataset: 0.50, Accuracy: 5979/10000 (60%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.19\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.57\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.82\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.56\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.05\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.40\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 1.05\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.87\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.11\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.99\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 1.10\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.60\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.26\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.65\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.42\n",
      "\n",
      "Average loss for Test dataset: 0.48, Accuracy: 6079/10000 (61%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.38\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.51\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.46\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.19\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.86\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.53\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.40\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.68\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.20\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.21\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.40\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.37\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.48\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.44\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.83\n",
      "\n",
      "Average loss for Test dataset: 0.47, Accuracy: 6138/10000 (61%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.99\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.62\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.17\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.07\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.44\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.87\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.13\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 1.33\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.57\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.91\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.75\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.76\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.15\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.91\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.44\n",
      "\n",
      "Average loss for Test dataset: 0.44, Accuracy: 6251/10000 (63%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.52\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.26\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.04\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.93\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.00\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.44\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.37\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.37\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.03\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.13\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.48\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.07\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.06\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.34\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.49\n",
      "\n",
      "Average loss for Test dataset: 0.45, Accuracy: 6227/10000 (62%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.57\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.10\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.32\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.36\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.81\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.38\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.03\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.91\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.08\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.43\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.16\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 1.05\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.41\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.76\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.03\n",
      "\n",
      "Average loss for Test dataset: 0.42, Accuracy: 6336/10000 (63%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.51\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.22\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.25\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.01\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.94\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.18\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.07\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.02\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.36\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.62\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.01\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.44\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.65\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.61\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.84\n",
      "\n",
      "Average loss for Test dataset: 0.42, Accuracy: 6334/10000 (63%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.65\n",
      "Train Epoch: 11 [4000/60000 (7%)]\tLoss: 0.40\n",
      "Train Epoch: 11 [8000/60000 (13%)]\tLoss: 0.58\n",
      "Train Epoch: 11 [12000/60000 (20%)]\tLoss: 0.21\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.02\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 0.51\n",
      "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.53\n",
      "Train Epoch: 11 [28000/60000 (47%)]\tLoss: 0.09\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.56\n",
      "Train Epoch: 11 [36000/60000 (60%)]\tLoss: 0.48\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 0.37\n",
      "Train Epoch: 11 [44000/60000 (73%)]\tLoss: 0.35\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.01\n",
      "Train Epoch: 11 [52000/60000 (87%)]\tLoss: 0.58\n",
      "Train Epoch: 11 [56000/60000 (93%)]\tLoss: 0.43\n",
      "\n",
      "Average loss for Test dataset: 0.41, Accuracy: 6477/10000 (65%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.09\n",
      "Train Epoch: 12 [4000/60000 (7%)]\tLoss: 0.41\n",
      "Train Epoch: 12 [8000/60000 (13%)]\tLoss: 0.18\n",
      "Train Epoch: 12 [12000/60000 (20%)]\tLoss: 0.24\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.68\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 0.42\n",
      "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.23\n",
      "Train Epoch: 12 [28000/60000 (47%)]\tLoss: 0.11\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.35\n",
      "Train Epoch: 12 [36000/60000 (60%)]\tLoss: 1.00\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 0.35\n",
      "Train Epoch: 12 [44000/60000 (73%)]\tLoss: 0.60\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.06\n",
      "Train Epoch: 12 [52000/60000 (87%)]\tLoss: 0.55\n",
      "Train Epoch: 12 [56000/60000 (93%)]\tLoss: 0.59\n",
      "\n",
      "Average loss for Test dataset: 0.41, Accuracy: 6364/10000 (64%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.55\n",
      "Train Epoch: 13 [4000/60000 (7%)]\tLoss: 0.89\n",
      "Train Epoch: 13 [8000/60000 (13%)]\tLoss: 0.45\n",
      "Train Epoch: 13 [12000/60000 (20%)]\tLoss: 0.37\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.11\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 0.44\n",
      "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.85\n",
      "Train Epoch: 13 [28000/60000 (47%)]\tLoss: 0.02\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.03\n",
      "Train Epoch: 13 [36000/60000 (60%)]\tLoss: 0.01\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 0.01\n",
      "Train Epoch: 13 [44000/60000 (73%)]\tLoss: 0.12\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.10\n",
      "Train Epoch: 13 [52000/60000 (87%)]\tLoss: 0.01\n",
      "Train Epoch: 13 [56000/60000 (93%)]\tLoss: 0.46\n",
      "\n",
      "Average loss for Test dataset: 0.40, Accuracy: 6452/10000 (65%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.45\n",
      "Train Epoch: 14 [4000/60000 (7%)]\tLoss: 0.02\n",
      "Train Epoch: 14 [8000/60000 (13%)]\tLoss: 0.38\n",
      "Train Epoch: 14 [12000/60000 (20%)]\tLoss: 0.20\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.32\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 0.00\n",
      "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.03\n",
      "Train Epoch: 14 [28000/60000 (47%)]\tLoss: 0.32\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 1.65\n",
      "Train Epoch: 14 [36000/60000 (60%)]\tLoss: 0.60\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 0.03\n",
      "Train Epoch: 14 [44000/60000 (73%)]\tLoss: 1.07\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.33\n",
      "Train Epoch: 14 [52000/60000 (87%)]\tLoss: 0.71\n",
      "Train Epoch: 14 [56000/60000 (93%)]\tLoss: 0.04\n",
      "\n",
      "Average loss for Test dataset: 0.40, Accuracy: 6487/10000 (65%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.43\n",
      "Train Epoch: 15 [4000/60000 (7%)]\tLoss: 0.05\n",
      "Train Epoch: 15 [8000/60000 (13%)]\tLoss: 0.58\n",
      "Train Epoch: 15 [12000/60000 (20%)]\tLoss: 0.01\n",
      "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.40\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 0.38\n",
      "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 0.04\n",
      "Train Epoch: 15 [28000/60000 (47%)]\tLoss: 0.84\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.14\n",
      "Train Epoch: 15 [36000/60000 (60%)]\tLoss: 0.28\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 0.47\n",
      "Train Epoch: 15 [44000/60000 (73%)]\tLoss: 0.70\n",
      "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.68\n",
      "Train Epoch: 15 [52000/60000 (87%)]\tLoss: 0.47\n",
      "Train Epoch: 15 [56000/60000 (93%)]\tLoss: 1.45\n",
      "\n",
      "Average loss for Test dataset: 0.39, Accuracy: 6580/10000 (66%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.47\n",
      "Train Epoch: 16 [4000/60000 (7%)]\tLoss: 0.13\n",
      "Train Epoch: 16 [8000/60000 (13%)]\tLoss: 0.25\n",
      "Train Epoch: 16 [12000/60000 (20%)]\tLoss: 0.22\n",
      "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 1.46\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 0.12\n",
      "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.52\n",
      "Train Epoch: 16 [28000/60000 (47%)]\tLoss: 0.46\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.43\n",
      "Train Epoch: 16 [36000/60000 (60%)]\tLoss: 0.03\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 0.48\n",
      "Train Epoch: 16 [44000/60000 (73%)]\tLoss: 0.01\n",
      "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.36\n",
      "Train Epoch: 16 [52000/60000 (87%)]\tLoss: 0.00\n",
      "Train Epoch: 16 [56000/60000 (93%)]\tLoss: 0.35\n",
      "\n",
      "Average loss for Test dataset: 0.39, Accuracy: 6607/10000 (66%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.85\n",
      "Train Epoch: 17 [4000/60000 (7%)]\tLoss: 0.37\n",
      "Train Epoch: 17 [8000/60000 (13%)]\tLoss: 0.03\n",
      "Train Epoch: 17 [12000/60000 (20%)]\tLoss: 0.02\n",
      "Train Epoch: 17 [16000/60000 (27%)]\tLoss: 0.13\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 0.38\n",
      "Train Epoch: 17 [24000/60000 (40%)]\tLoss: 0.41\n",
      "Train Epoch: 17 [28000/60000 (47%)]\tLoss: 0.55\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.82\n",
      "Train Epoch: 17 [36000/60000 (60%)]\tLoss: 0.10\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 0.41\n",
      "Train Epoch: 17 [44000/60000 (73%)]\tLoss: 0.00\n",
      "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.03\n",
      "Train Epoch: 17 [52000/60000 (87%)]\tLoss: 0.53\n",
      "Train Epoch: 17 [56000/60000 (93%)]\tLoss: 0.31\n",
      "\n",
      "Average loss for Test dataset: 0.39, Accuracy: 6624/10000 (66%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.06\n",
      "Train Epoch: 18 [4000/60000 (7%)]\tLoss: 0.35\n",
      "Train Epoch: 18 [8000/60000 (13%)]\tLoss: 0.28\n",
      "Train Epoch: 18 [12000/60000 (20%)]\tLoss: 0.55\n",
      "Train Epoch: 18 [16000/60000 (27%)]\tLoss: 1.00\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 0.50\n",
      "Train Epoch: 18 [24000/60000 (40%)]\tLoss: 0.46\n",
      "Train Epoch: 18 [28000/60000 (47%)]\tLoss: 0.00\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.02\n",
      "Train Epoch: 18 [36000/60000 (60%)]\tLoss: 1.04\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 0.04\n",
      "Train Epoch: 18 [44000/60000 (73%)]\tLoss: 0.04\n",
      "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.08\n",
      "Train Epoch: 18 [52000/60000 (87%)]\tLoss: 0.99\n",
      "Train Epoch: 18 [56000/60000 (93%)]\tLoss: 0.00\n",
      "\n",
      "Average loss for Test dataset: 0.38, Accuracy: 6628/10000 (66%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.04\n",
      "Train Epoch: 19 [4000/60000 (7%)]\tLoss: 1.12\n",
      "Train Epoch: 19 [8000/60000 (13%)]\tLoss: 0.69\n",
      "Train Epoch: 19 [12000/60000 (20%)]\tLoss: 0.01\n",
      "Train Epoch: 19 [16000/60000 (27%)]\tLoss: 1.11\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 0.52\n",
      "Train Epoch: 19 [24000/60000 (40%)]\tLoss: 0.23\n",
      "Train Epoch: 19 [28000/60000 (47%)]\tLoss: 0.52\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.83\n",
      "Train Epoch: 19 [36000/60000 (60%)]\tLoss: 0.73\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 0.41\n",
      "Train Epoch: 19 [44000/60000 (73%)]\tLoss: 1.07\n",
      "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.03\n",
      "Train Epoch: 19 [52000/60000 (87%)]\tLoss: 0.05\n"
     ]
    }
   ],
   "source": [
    "with mf.start_run():\n",
    "    \n",
    "    mf_output_dir   = 'tmp/'\n",
    "    os.makedirs(mf_output_dir, exist_ok=True)\n",
    "    mf.log_params(args)\n",
    "\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "    \n",
    "    mf.pytorch.log_model(model, \"model\")\n",
    "    mf.log_artifacts(mf_output_dir)\n",
    "    shutil.rmtree(mf_output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
